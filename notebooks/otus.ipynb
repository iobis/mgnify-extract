{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MGnify to Darwin Core export notes\n",
    "## How are OTUs derived in the MGnify pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mgnifyextract.analyses import get_analysis\n",
    "from mgnifyextract.downloads import FastaDownload, MseqDownload, TsvDownload\n",
    "from mgnifyextract.studies import get_superstudy_studies\n",
    "from mgnifyextract.util import clean_taxonomy_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Analysis https://www.ebi.ac.uk/metagenomics/analyses/MGYA00593805>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis = get_analysis(\"MGYA00593805\")\n",
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloads = analysis.get_downloads()\n",
    "\n",
    "marker = \"SSU\"\n",
    "\n",
    "fasta_files = [download for download in downloads if isinstance(download, FastaDownload) and download.marker == marker]\n",
    "mseq_files = [download for download in downloads if isinstance(download, MseqDownload) and download.marker == marker]\n",
    "tsv_files = [download for download in downloads if isinstance(download, TsvDownload) and download.marker == marker]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the number of rows in the mseq and OTU files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12178 entries, 0 to 12177\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   #query       12178 non-null  object \n",
      " 1   dbhit        12178 non-null  object \n",
      " 2   bitscore     12178 non-null  int64  \n",
      " 3   identity     12178 non-null  float64\n",
      " 4   matches      12178 non-null  int64  \n",
      " 5   mismatches   12178 non-null  int64  \n",
      " 6   gaps         12178 non-null  int64  \n",
      " 7   query_start  12178 non-null  int64  \n",
      " 8   query_end    12178 non-null  int64  \n",
      " 9   dbhit_start  12178 non-null  int64  \n",
      " 10  dbhit_end    12178 non-null  int64  \n",
      " 11  strand       12178 non-null  object \n",
      " 12  Unnamed: 12  0 non-null      float64\n",
      " 13  SILVA        12178 non-null  object \n",
      " 14  Unnamed: 14  0 non-null      float64\n",
      "dtypes: float64(3), int64(8), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "mseq = mseq_files[0].read()\n",
    "mseq.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 121 entries, 0 to 120\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   # OTU ID  121 non-null    int64  \n",
      " 1   SSU_rRNA  121 non-null    float64\n",
      " 2   taxonomy  121 non-null    object \n",
      " 3   taxid     121 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 3.9+ KB\n"
     ]
    }
   ],
   "source": [
    "otu = tsv_files[0].read()\n",
    "otu.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same number of distinct taxonomy values in the mseq file as well as the OTU suggests that the OTUs correspond to all distinct taxonomic assignments regardless of sequence similarity. All reads with assignment Bacteria for example are collapsed into a single OTU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([clean_taxonomy_string(tax) for tax in otu[\"taxonomy\"]]).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([clean_taxonomy_string(tax) for tax in mseq[\"SILVA\"]]).nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative approach\n",
    "\n",
    "Instead of relying on the OTU table as downloaded from MGnify, let's try grouping sequences by SILVA hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Study https://www.ebi.ac.uk/metagenomics/studies/MGYS00005780 >"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = get_superstudy_studies(\"atlanteco\")[0]\n",
    "study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sample https://www.ebi.ac.uk/metagenomics/samples/SRS2329696 >"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = study.get_samples(max_results=1)[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Run https://www.ebi.ac.uk/metagenomics/runs/SRR5788044 xx>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = sample.get_runs(max_results=1)[0]\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Analysis https://www.ebi.ac.uk/metagenomics/analyses/MGYA00463299>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis = run.get_analyses(max_results=1)[0]\n",
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker = \"LSU\"\n",
    "downloads = analysis.get_downloads()\n",
    "fasta_files = [download for download in downloads if isinstance(download, FastaDownload) and download.marker == marker]\n",
    "mseq_files = [download for download in downloads if isinstance(download, MseqDownload) and download.marker == marker]\n",
    "fasta = fasta_files[0].read_pandas()\n",
    "mseq = mseq_files[0].read()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge fasta and mseq tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fasta.merge(mseq.rename({\"#query\": \"reference\"}, axis=1), how=\"left\", on=\"reference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First clean taxonomy strings by removing empty ranks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SILVA\"] = [clean_taxonomy_string(tax) for tax in df[\"SILVA\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the number of distinct sequences, taxonomy strings, and DB hits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42037"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sequence\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"SILVA\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3184"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"dbhit\"].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So an alternative approach would be to group sequences by DB hit, and pick a random representative sequence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "314a97c846296f63d0e4efa7147ce547b99d51e3f641193b55b463cff9afbb5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
